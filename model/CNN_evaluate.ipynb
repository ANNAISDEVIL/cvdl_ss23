{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pygame\n",
    "import json \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_FOLDER_NAME = \"./CNN_noto_sans\"\n",
    "# PATH_MODEL = PATH_FOLDER_NAME + \"/CNN.pth\"\n",
    "# font_str = \"noto_sans\"\n",
    "\n",
    "# PATH_FOLDER_NAME = \"./CNN_08_11_18_04_00_typographer\"\n",
    "# PATH_MODEL = PATH_FOLDER_NAME + \"/CNN__typographer.pth\"\n",
    "# font_str = \"typographer\"\n",
    "\n",
    "# PATH_FOLDER_NAME = \"./CNN_08_11_18_17_53_turok\"\n",
    "# PATH_MODEL = PATH_FOLDER_NAME + \"/CNN__turok.pth\"\n",
    "# font_str = \"turok\"\n",
    "\n",
    "PATH_FOLDER_NAME = \"./CNN_08_11_18_28_03_mandatory\"\n",
    "PATH_MODEL = PATH_FOLDER_NAME + \"/CNN__mandatory.pth\"\n",
    "font_str = \"mandatory\"\n",
    "\n",
    "DO_EVAL_ORI = False\n",
    "# DO_EVAL_ORI = True\n",
    "\n",
    "NOISE_TYPE  = \"greek\"\n",
    "NOISE_TYPE  = \"cyrillic\"\n",
    "NOISE_TYPE  = \"leetspeak\"\n",
    "\n",
    "NOISE_P     = 0.5\n",
    "# NOISE_P     = 0.4\n",
    "# NOISE_P     = 0.3\n",
    "# NOISE_P     = 0.2\n",
    "# NOISE_P     = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_FOLDER_NAME+\"/config.json\",'r',encoding='utf-8') as f :\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "SEED                = CONFIG[\"seed\"]\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "SCREEN_WIDTH        = CONFIG[\"screen_width\"]\n",
    "SCREEN_HEIGHT       = CONFIG[\"screen_height\"]\n",
    "FONT_SIZE           = CONFIG[\"font_size\"]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_OUT_CHANNELS      = CONFIG[\"model_out_channels\"]\n",
    "MODEL_KERNEL_SIZE       = CONFIG[\"model_kernel_size\"]\n",
    "MODEL_SITRIDE           = CONFIG[\"model_sitride\"]\n",
    "MODEL_PADDING           = CONFIG[\"model_padding\"]\n",
    "MODEL_LINEAR_SIZE       = CONFIG[\"model_linear_size\"]\n",
    "\n",
    "DEV_BATCH_SIZE          = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_PATH_Noto_sans     = \"../converttext/noto-sans.regular.ttf\"\n",
    "FONT_PATH_Typographer   = \"../converttext/TypographerTextur-Regular.ttf\"\n",
    "FONT_PATH_Turok         = \"../converttext/turok.ttf\"\n",
    "FONT_PATH_Mandatory     = \"../converttext/mandatory.ttf\"\n",
    "PATH_WORD_NUM_DICT  = './word_num_dict.json'\n",
    "PATH_WORD_TO_ID     = './word_to_id_dict.json'\n",
    "PATH_ID_TO_WORD     = './id_to_word_dict.json'\n",
    "\n",
    "PATH_EVALUATE_DATA_PREFIX   = f\"./{PATH_FOLDER_NAME}/eval_data\"\n",
    "\n",
    "# evaluation\n",
    "PATH_NOISE_DICT_LEETSPEAK   = \"./letter_to_leetspeak.json\"\n",
    "PATH_NOISE_DICT_GREEK       = \"./letter_to_greek_dict.json\"\n",
    "PATH_NOISE_DICT_CYRILLIC    = \"./letter_to_cyrillic_dict.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_channels=6, kernel_size=1, stride=1, padding=0, vocab_size=5000, linear_size=5000, normalization=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=out_channels, \n",
    "            kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(linear_size, vocab_size) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "\n",
    "font_noto_sans_regular  = pygame.font.Font(FONT_PATH_Noto_sans, FONT_SIZE)\n",
    "font_noto_typographer   = pygame.font.Font(FONT_PATH_Typographer, FONT_SIZE)\n",
    "font_noto_turok         = pygame.font.Font(FONT_PATH_Turok, FONT_SIZE)\n",
    "font_noto_mandatory     = pygame.font.Font(FONT_PATH_Mandatory, FONT_SIZE)\n",
    "\n",
    "\n",
    "def to_image(text:str, font_str=\"noto_sans\", id:int=None, noise=False, noise_type=None, noise_original_word=\"\"):\n",
    "  # pygame.init()\n",
    "  # screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "  if font_str == \"noto_sans\":\n",
    "    font = font_noto_sans_regular\n",
    "  if font_str == \"typographer\":\n",
    "    font = font_noto_typographer\n",
    "  if font_str == \"turok\":\n",
    "    font = font_noto_turok\n",
    "  if font_str == \"mandatory\":\n",
    "    font = font_noto_mandatory\n",
    "  \n",
    "  \n",
    "  screen = pygame.Surface((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "  screen.fill((255, 255, 255))\n",
    "  # draw image\n",
    "  img = font.render(str(text), True, (0, 0, 0))\n",
    "  screen.blit(img, (2, 0))\n",
    "  for event in pygame.event.get():\n",
    "    if event.type == pygame.QUIT:\n",
    "      run = False\n",
    "  # pygame.display.flip() \n",
    "  # Save the screen as an image when the program finishes\n",
    "  if noise == False:\n",
    "    # TODO: obtain font name\n",
    "    filename = f\"./temp_image/word_{str(id)}_{str(text)}_{font_str}.png\"\n",
    "  else:\n",
    "    filename = f\"./temp_image/word_{str(id)}_{str(noise_original_word)}_{font_str}_noised_{noise_type}.png\"\n",
    "  pygame.image.save(screen, filename)\n",
    "  # print(\"Screen saved as \", filename)\n",
    "  # pygame.quit()\n",
    "  return filename\n",
    "\n",
    "# image_path = to_image(text=\"1nd1st1nguishÎ±ble\", font_str=\"noto_sans\", id=5, noise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test load: length of word_num_dict: 4572\n",
      "test load: length of word_to_id_dict_test: 4572\n",
      "test load: length of id_to_word_dict_test: 4572\n",
      "note index needs to use str(index)\n",
      "test load: index: [5], word in id_to_word_dict: [defines], id in word_id_dict: [5]\n"
     ]
    }
   ],
   "source": [
    "# load dictionary\n",
    "\n",
    "with open(PATH_WORD_NUM_DICT, 'r') as fp:\n",
    "    word_num_dict_test = json.load(fp)\n",
    "with open(PATH_WORD_TO_ID, 'r') as fp:\n",
    "    word_to_id_dict_test = json.load(fp)\n",
    "with open(PATH_ID_TO_WORD, 'r') as fp:\n",
    "    id_to_word_dict_test = json.load(fp)\n",
    "    \n",
    "print(\"test load: length of word_num_dict:\", len(word_num_dict_test.keys()))\n",
    "print(\"test load: length of word_to_id_dict_test:\", len(word_to_id_dict_test.keys()))\n",
    "print(\"test load: length of id_to_word_dict_test:\", len(id_to_word_dict_test.keys()))\n",
    "print('note index needs to use str(index)')\n",
    "print(f\"test load: index: [5], word in id_to_word_dict: [{id_to_word_dict_test[str(5)]}], id in word_id_dict: [{word_to_id_dict_test[id_to_word_dict_test['5']]}]\")\n",
    "\n",
    "VOCAB_SIZE = len(word_num_dict_test.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class WordImageIDDataset(Dataset):\n",
    "    def __init__(self, word_to_id_list, font_str, noise=False):\n",
    "        self.word_to_id_list = word_to_id_list\n",
    "        self.font_str = font_str\n",
    "        self.noise = noise\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word_to_id_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ''' index is not token ID '''\n",
    "        output_word = self.word_to_id_list[index][0]\n",
    "        image_path  = to_image(\n",
    "            text    = output_word, \n",
    "            font_str= self.font_str,\n",
    "            id      = index, \n",
    "            noise   = self.noise\n",
    "            )\n",
    "        \n",
    "        # for path in image_paths:\n",
    "        output_img = Image.open(image_path).convert('L')\n",
    "        output_img = transform_norm(output_img)\n",
    "        id = self.word_to_id_list[index][1]\n",
    "        # output_id_onehot = torch.zeros(1, VOCAB_SIZE)\n",
    "        # output_id_onehot[0][id] = 1\n",
    "        output_id_onehot = torch.zeros(VOCAB_SIZE)\n",
    "        output_id_onehot[id] = 1\n",
    "                \n",
    "        output = {'word'    : output_word,\n",
    "                  'image'   : output_img,\n",
    "                  'id'      : output_id_onehot}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the final accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WordImageIDDataset(\n",
    "    word_to_id_list = list(word_to_id_dict_test.items()),\n",
    "    font_str=font_str,\n",
    "    noise=False)\n",
    "eval_dataloader = DataLoader(dataset, batch_size=DEV_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if DO_EVAL_ORI:\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        all_word_list       = []\n",
    "        all_id_list         = []\n",
    "        all_pred_id_list    = []\n",
    "        all_compare_list    = []\n",
    "        \n",
    "        for data in eval_dataloader:\n",
    "            words    = data['word']     # list\n",
    "            imgs     = data['image']\n",
    "            ids      = data['id']\n",
    "            \n",
    "            outputs = model(imgs.to(device))\n",
    "            _, targets = torch.max(ids.data, 1)         # torch.Size([16])\n",
    "            _, predicted = torch.max(outputs.data, 1)   # torch.Size([16])\n",
    "            total += targets.size(0)\n",
    "            compare = predicted == targets.to(device)\n",
    "            correct += compare.sum().item()             # torch.Size([16])\n",
    "            \n",
    "            all_word_list.extend(words)\n",
    "            all_id_list.extend(targets.tolist())\n",
    "            all_pred_id_list.extend(predicted.tolist())\n",
    "            all_compare_list.extend(compare.tolist())\n",
    "        evaluate_acc = correct/total\n",
    "        print(evaluate_acc)\n",
    "        print(all_word_list   )\n",
    "        print(all_id_list     )\n",
    "        print(all_pred_id_list   )\n",
    "        print(all_compare_list)\n",
    "        all_pred_word_list = [id_to_word_dict_test[str(pred_id)] for pred_id in all_pred_id_list]\n",
    "        print(all_pred_word_list)\n",
    "\n",
    "        evaluate_data = pd.DataFrame({'word':all_word_list,\n",
    "                            'real_id':all_id_list,\n",
    "                            'pred_word':all_pred_word_list,\n",
    "                            'pred_id':all_pred_id_list,\n",
    "                            'eval':all_compare_list,\n",
    "                            })\n",
    "\n",
    "        evaluate_data.to_csv(PATH_EVALUATE_DATA_PREFIX+f\"_{round(evaluate_acc*100, 2)}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of different proportion of noise\n",
    "\n",
    "leetspeak: https://github.com/floft/leetspeak/blob/master/LeetSpeak.py\n",
    "\n",
    "unicode (Cyrillic): https://www.russlandjournal.de/en/learn-russian/russian-alphabet/\n",
    "\n",
    "unicode (greek): https://web.mit.edu/jmorzins/www/greek-alphabet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordImageID_Noise_Dataset(Dataset):\n",
    "    def __init__(self, word_to_id_list, font_str:str=\"noto_sans\", isNoise:bool=False, noise_dict=None, noise_p:float=0.5, noise_type:str=\"\"):\n",
    "        self.word_to_id_list = word_to_id_list\n",
    "        # self.font       = font\n",
    "        self.font_str   = font_str\n",
    "        self.isNoise    = isNoise\n",
    "        self.noise_dict = noise_dict\n",
    "        self.noise_p    = noise_p\n",
    "        self.noise_type = noise_type\n",
    "        if isNoise:\n",
    "            if noise_dict == None:\n",
    "                print(\"Error: noise_dict is None, while isNoise is True\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word_to_id_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ''' index is not token ID '''\n",
    "        output_word_original = self.word_to_id_list[index][0]\n",
    "        output_word_noised   = \"\"\n",
    "        output_word_length   = len(output_word_original)\n",
    "        output_noise_length  = 0\n",
    "        if self.isNoise: # create noise word\n",
    "            output_word_noised = \"\"\n",
    "            for letter in output_word_original:\n",
    "                p = random.random()\n",
    "                if p < self.noise_p:\n",
    "                    try:\n",
    "                        if self.noise_dict[letter] != \"\":    \n",
    "                            output_word_noised += self.noise_dict[letter]\n",
    "                            output_noise_length += 1\n",
    "                        else:\n",
    "                            # case: no approperate noise defined for this letter\n",
    "                            output_word_noised += letter\n",
    "                    except Exception:\n",
    "                        # TODO: letter OOV problem\n",
    "                        print(f\"Warning: [{letter}] from [{output_word_original}] is not an English letter\")\n",
    "                        output_word_noised += letter\n",
    "                else:\n",
    "                    output_word_noised += letter\n",
    "        if self.isNoise: # select which word to render\n",
    "            word_for_render = output_word_noised\n",
    "        else:\n",
    "            word_for_render = output_word_original\n",
    "        \n",
    "        word_id = self.word_to_id_list[index][1]     \n",
    "        image_path  = to_image(     # TODO: original word in file name\n",
    "            text    = word_for_render, \n",
    "            font_str= self.font_str,\n",
    "            id      = word_id,          # TODO: here should be ID\n",
    "            noise   = self.isNoise,     # TODO: noise -> isNoise\n",
    "            noise_original_word = output_word_original,\n",
    "            noise_type = self.noise_type,\n",
    "        )\n",
    "\n",
    "        # for path in image_paths:\n",
    "        output_img = Image.open(image_path).convert('L')\n",
    "        output_img = transform_norm(output_img)\n",
    "        \n",
    "        output_id_onehot = torch.zeros(VOCAB_SIZE)\n",
    "        output_id_onehot[word_id] = 1\n",
    "                \n",
    "        output = {'word'        : output_word_original,\n",
    "                  'word_noised' : output_word_noised,\n",
    "                  'image'       : output_img,\n",
    "                  'id'          : output_id_onehot,\n",
    "                  'word_length' : str(output_word_length),\n",
    "                  'noise_length': str(output_noise_length),\n",
    "                  'noise_pers'  : str(round((output_noise_length / output_word_length)*100, 2))\n",
    "                  }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of noise dict leetspeak: 52\n",
      "length of noise dict greek: 52\n",
      "length of noise dict cyrillic: 52\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_NOISE_DICT_LEETSPEAK, 'r', encoding=\"utf-8\") as fp:\n",
    "    noise_dict_leetspeak = json.load(fp)\n",
    "with open(PATH_NOISE_DICT_GREEK, 'r', encoding=\"utf-8\") as fp:\n",
    "    noise_dict_greek = json.load(fp)\n",
    "with open(PATH_NOISE_DICT_CYRILLIC, 'r', encoding=\"utf-8\") as fp:\n",
    "    noise_dict_cyrillic = json.load(fp)\n",
    "\n",
    "print(\"length of noise dict leetspeak:\", len(noise_dict_leetspeak.keys()))\n",
    "print(\"length of noise dict greek:\", len(noise_dict_greek.keys()))\n",
    "print(\"length of noise dict cyrillic:\", len(noise_dict_cyrillic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOISE_TYPE == \"leetspeak\":\n",
    "    noise_dict = noise_dict_leetspeak\n",
    "if NOISE_TYPE == \"greek\":\n",
    "    noise_dict = noise_dict_greek\n",
    "if NOISE_TYPE == \"cyrillic\":\n",
    "    noise_dict = noise_dict_cyrillic\n",
    "    \n",
    "dataset_eval_noise = WordImageID_Noise_Dataset(\n",
    "    word_to_id_list = list(word_to_id_dict_test.items()),\n",
    "    # font        = font_noto_sans_regular,\n",
    "    font_str    = font_str,\n",
    "    isNoise     = True, \n",
    "    noise_dict  = noise_dict,\n",
    "    noise_p     = NOISE_P,\n",
    "    noise_type  = NOISE_TYPE,\n",
    "    )\n",
    "eval_noise_dataloader = DataLoader(dataset_eval_noise, batch_size=DEV_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: [Ã³] from [BartÃ³k] is not an English letter\n",
      "Warning: [Ã¯] from [HaÃ¯ba] is not an English letter\n",
      "0.20406824146981628\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    all_word_list        = []\n",
    "    all_word_noised_list = []\n",
    "    all_id_list          = []\n",
    "    all_word_length_list = []\n",
    "    all_noise_length_list= []\n",
    "    all_noises_pers      = []\n",
    "    all_pred_id_list     = []\n",
    "    all_compare_list     = []\n",
    "    \n",
    "    for data in eval_noise_dataloader:\n",
    "        # data = next(iter(eval_dataloader))\n",
    "        words    = data['word']     # list\n",
    "        imgs     = data['image']\n",
    "        ids      = data['id']\n",
    "        words_noised    = data['word_noised']\n",
    "        words_length    = data['word_length']\n",
    "        noises_length   = data['noise_length']\n",
    "        noises_pers     = data['noise_pers']\n",
    "        \n",
    "        outputs = model(imgs.to(device))\n",
    "        _, targets = torch.max(ids.data, 1)         # torch.Size([16])\n",
    "        _, predicted = torch.max(outputs.data, 1)   # torch.Size([16])\n",
    "        # print(\"words: \", len(words))\n",
    "        # print(\"ids: \", ids.shape)\n",
    "        # print(\"targets: \", targets.shape)\n",
    "        # print(\"targets: \", targets.tolist())\n",
    "        # print(\"outputs: \", outputs.shape)\n",
    "        # print(\"predicted: \", predicted.shape)\n",
    "        total += targets.size(0)\n",
    "        compare = predicted == targets.to(device)\n",
    "        # print(\"compare: \", compare.shape)\n",
    "        correct += compare.sum().item()             # torch.Size([16])\n",
    "        \n",
    "        all_word_list.extend(words)\n",
    "        all_word_noised_list.extend(words_noised)\n",
    "        all_id_list.extend(targets.tolist())\n",
    "        all_word_length_list.extend(words_length)\n",
    "        all_noise_length_list.extend(noises_length)\n",
    "        all_noises_pers.extend(noises_pers)\n",
    "        all_pred_id_list.extend(predicted.tolist())\n",
    "        all_compare_list.extend(compare.tolist())\n",
    "        # print(\"targets: \", targets)\n",
    "        # print(\"predicted: \", predicted)\n",
    "        # print(\"correct: \", correct)\n",
    "        # break\n",
    "    evaluate_acc = correct/total\n",
    "    print(evaluate_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n",
      "4572\n"
     ]
    }
   ],
   "source": [
    "print(len(all_word_list        ))\n",
    "print(len(all_word_noised_list ))\n",
    "print(len(all_id_list          ))\n",
    "print(len(all_word_length_list ))\n",
    "print(len(all_noise_length_list))\n",
    "print(len(all_noises_pers      ))\n",
    "print(len(all_pred_id_list     ))\n",
    "print(len(all_compare_list     ))\n",
    "\n",
    "\n",
    "all_pred_word_list = [id_to_word_dict_test[str(pred_id)] for pred_id in all_pred_id_list]\n",
    "print(len(all_pred_word_list))\n",
    "\n",
    "evaluate_noise_data = pd.DataFrame({\n",
    "    'word'      : all_word_list,\n",
    "    'real_id'   : all_id_list,\n",
    "    'noise_word': all_word_noised_list,\n",
    "    'pred_word' : all_pred_word_list,\n",
    "    'pred_id'   : all_pred_id_list,\n",
    "    'eval'      : all_compare_list,\n",
    "    'word_len'  : all_word_length_list,\n",
    "    \"noise_len\" : all_noise_length_list,\n",
    "    \"noise_pers\": all_noises_pers\n",
    "    })\n",
    "\n",
    "evaluate_noise_data.to_csv(PATH_EVALUATE_DATA_PREFIX+f\"_{font_str}_{NOISE_TYPE}_p{NOISE_P}_{round(evaluate_acc*100, 2)}_s{SEED}.csv\", \n",
    "                           encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39env",
   "language": "python",
   "name": "py39env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
