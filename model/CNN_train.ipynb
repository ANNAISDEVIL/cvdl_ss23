{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pygame\n",
    "import json \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_channels=6, kernel_size=1, stride=1, padding=0, vocab_size=5000, linear_size=5000, normalization=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=out_channels, \n",
    "            kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(linear_size, vocab_size) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SCREEN_WIDTH    = 100\n",
    "# SCREEN_HEIGHT   = 20\n",
    "# FONT_SIZE       = 10 \n",
    "\n",
    "SCREEN_WIDTH    = 130\n",
    "SCREEN_HEIGHT   = 25\n",
    "FONT_SIZE       = 15 \n",
    "# 4680\n",
    "\n",
    "pygame.init()\n",
    "font_noto_sans_regular = pygame.font.Font(\"../converttext/noto-sans.regular.ttf\", FONT_SIZE)\n",
    "\n",
    "\n",
    "def to_image(text:str, font, id:int=None, noise=False):\n",
    "  # pygame.init()\n",
    "  # screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "  screen = pygame.Surface((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "  screen.fill((255, 255, 255))\n",
    "  # draw image\n",
    "  img = font.render(str(text), True, (0, 0, 0))\n",
    "  screen.blit(img, (2, 0))\n",
    "  for event in pygame.event.get():\n",
    "    if event.type == pygame.QUIT:\n",
    "      run = False\n",
    "  # pygame.display.flip() \n",
    "  # Save the screen as an image when the program finishes\n",
    "  if noise == False:\n",
    "    filename = f\"./temp_image/word_{str(id)}_{str(text)}_notoSans.png\"\n",
    "  else:\n",
    "    filename = f\"./temp_image/word_{str(id)}_{str(text)}_notoSans_noised.png\"\n",
    "  pygame.image.save(screen, filename)\n",
    "  # print(\"Screen saved as \", filename)\n",
    "  # pygame.quit()\n",
    "  return filename\n",
    "\n",
    "image_path = to_image(text=\"1nd1st1nguishÎ±ble\", font=font_noto_sans_regular, id=5, noise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionary\n",
    "\n",
    "with open('word_num_dict.json', 'r') as fp:\n",
    "    word_num_dict_test = json.load(fp)\n",
    "with open('word_to_id_dict.json', 'r') as fp:\n",
    "    word_to_id_dict_test = json.load(fp)\n",
    "with open('id_to_word_dict.json', 'r') as fp:\n",
    "    id_to_word_dict_test = json.load(fp)\n",
    "    \n",
    "print(\"test load: length of word_num_dict:\", len(word_num_dict_test.keys()))\n",
    "print(\"test load: length of word_to_id_dict_test:\", len(word_to_id_dict_test.keys()))\n",
    "print(\"test load: length of id_to_word_dict_test:\", len(id_to_word_dict_test.keys()))\n",
    "print('note index needs to use str(index)')\n",
    "print(f\"test load: index: [5], word in id_to_word_dict: [{id_to_word_dict_test[str(5)]}], id in word_id_dict: [{word_to_id_dict_test[id_to_word_dict_test['5']]}]\")\n",
    "\n",
    "VOCAB_SIZE = len(word_num_dict_test.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class WordImageIDDataset(Dataset):\n",
    "    def __init__(self, word_to_id_list, font, noise=False):\n",
    "        self.word_to_id_list = word_to_id_list\n",
    "        self.font = font\n",
    "        self.noise = noise\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word_to_id_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ''' index is not token ID '''\n",
    "        output_word = self.word_to_id_list[index][0]\n",
    "        image_path = to_image(\n",
    "            text=output_word, \n",
    "            font=self.font,\n",
    "            id=index, \n",
    "            noise=self.noise)\n",
    "        \n",
    "        # for path in image_paths:\n",
    "        output_img = Image.open(image_path).convert('L')\n",
    "        output_img = transform_norm(output_img)\n",
    "        id = self.word_to_id_list[index][1]\n",
    "        # output_id_onehot = torch.zeros(1, VOCAB_SIZE)\n",
    "        # output_id_onehot[0][id] = 1\n",
    "        output_id_onehot = torch.zeros(VOCAB_SIZE)\n",
    "        output_id_onehot[id] = 1\n",
    "                \n",
    "        output = {'word'    : output_word,\n",
    "                  'image'   : output_img,\n",
    "                  'id'      : output_id_onehot}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(out_channels=16, kernel_size=3, stride=1, padding=1, vocab_size=VOCAB_SIZE, normalization=False, linear_size=12480).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataset = WordImageIDDataset(word_to_id_list = list(word_to_id_dict_test.items()),\n",
    "                            font=font_noto_sans_regular,\n",
    "                            noise=False)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    epoch_loss = []\n",
    "    for data in dataloader:\n",
    "        words    = data['word']\n",
    "        imgs     = data['image']\n",
    "        ids      = data['id']\n",
    "        optimizer.zero_grad()\n",
    "        # print(word)\n",
    "        # print(imgs.shape)\n",
    "        # print(id)\n",
    "        # print(ids.shape)\n",
    "        # read image    \n",
    "        outputs = model(imgs.to(device))\n",
    "        # print(output)\n",
    "        softmax = torch.nn.Softmax()\n",
    "        # outputs = softmax(outputs)\n",
    "        # print(pred) \n",
    "        # print(preds.shape)\n",
    "        # print(ids.shape)\n",
    "        \n",
    "        loss = criterion(outputs, ids.to(device))\n",
    "        # print(\"Loss:\", loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # torch.cuda.empty_cache()\n",
    "    print(sum(epoch_loss)/len(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./CNN_130_250_15_16_3_1_1.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
